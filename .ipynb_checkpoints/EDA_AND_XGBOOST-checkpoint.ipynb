{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASIC EXPLORATORY DATA ANALYSIS/CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read in train and test as Pandas DataFrames\n",
    "\"\"\"\n",
    "df_train = pd.read_csv(\"train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>feat_009</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_248</th>\n",
       "      <th>feat_249</th>\n",
       "      <th>feat_250</th>\n",
       "      <th>feat_251</th>\n",
       "      <th>feat_252</th>\n",
       "      <th>feat_253</th>\n",
       "      <th>feat_254</th>\n",
       "      <th>feat_255</th>\n",
       "      <th>feat_256</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  feat_001  feat_002  \\\n",
       "0  c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...         0         0   \n",
       "1  C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...         1         0   \n",
       "2  [nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...         1         0   \n",
       "3  [nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...         1         0   \n",
       "4     c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1         0         0   \n",
       "\n",
       "   feat_003  feat_004  feat_005  feat_006  feat_007  feat_008  feat_009  ...   \\\n",
       "0         0         0         1         0         1         0         0  ...    \n",
       "1         0         0         1         0         1         0         0  ...    \n",
       "2         0         0         1         1         1         0         0  ...    \n",
       "3         0         0         1         1         1         0         0  ...    \n",
       "4         0         0         1         0         1         0         0  ...    \n",
       "\n",
       "   feat_248  feat_249  feat_250  feat_251  feat_252  feat_253  feat_254  \\\n",
       "0         1         0         0         0         0         0         0   \n",
       "1         1         0         0         1         0         0         0   \n",
       "2         1         0         0         0         1         0         0   \n",
       "3         1         0         0         0         1         0         0   \n",
       "4         1         0         0         0         0         0         0   \n",
       "\n",
       "   feat_255  feat_256   gap  \n",
       "0         0         0  1.19  \n",
       "1         0         0  1.60  \n",
       "2         0         0  1.49  \n",
       "3         0         0  1.36  \n",
       "4         0         0  1.98  \n",
       "\n",
       "[5 rows x 258 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we check if there are any impossible response values (ie. negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_train.gap<0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove rows with negative (impossible) response values\n",
    "df_train=df_train[df_train.gap>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999997, 258)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response values are normally distributed as shown by the following histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEACAYAAABGYoqtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15cb4b6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response=df_train[df_train.gap>0].gap\n",
    "plt.hist(response, bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we calculate the parameters for the response data normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9157342872 0.407148592603\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# Fit a normal distribution to the data:\n",
    "mu, std = norm.fit(response)\n",
    "print mu, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulls=df_train.isnull().sum()\n",
    "sum(nulls>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values were found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we find the correlations (pearson) between the features (and response):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>feat_009</th>\n",
       "      <th>feat_010</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_248</th>\n",
       "      <th>feat_249</th>\n",
       "      <th>feat_250</th>\n",
       "      <th>feat_251</th>\n",
       "      <th>feat_252</th>\n",
       "      <th>feat_253</th>\n",
       "      <th>feat_254</th>\n",
       "      <th>feat_255</th>\n",
       "      <th>feat_256</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feat_001</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.002692</td>\n",
       "      <td>-0.093024</td>\n",
       "      <td>-0.083714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.395173</td>\n",
       "      <td>0.147003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.275221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_002</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_003</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_004</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_005</th>\n",
       "      <td>-0.002692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.022924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          feat_001  feat_002  feat_003  feat_004  feat_005  feat_006  \\\n",
       "feat_001  1.000000       NaN       NaN       NaN -0.002692 -0.093024   \n",
       "feat_002       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_003       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_004       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_005 -0.002692       NaN       NaN       NaN  1.000000  0.003448   \n",
       "\n",
       "          feat_007  feat_008  feat_009  feat_010    ...     feat_248  \\\n",
       "feat_001 -0.083714       NaN       NaN       NaN    ...    -0.111524   \n",
       "feat_002       NaN       NaN       NaN       NaN    ...          NaN   \n",
       "feat_003       NaN       NaN       NaN       NaN    ...          NaN   \n",
       "feat_004       NaN       NaN       NaN       NaN    ...          NaN   \n",
       "feat_005  0.022924       NaN       NaN       NaN    ...     0.012017   \n",
       "\n",
       "          feat_249  feat_250  feat_251  feat_252  feat_253  feat_254  \\\n",
       "feat_001       NaN       NaN  0.395173  0.147003       NaN       NaN   \n",
       "feat_002       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_003       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_004       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_005       NaN       NaN  0.001908  0.000710       NaN       NaN   \n",
       "\n",
       "          feat_255  feat_256       gap  \n",
       "feat_001       NaN       NaN -0.275221  \n",
       "feat_002       NaN       NaN       NaN  \n",
       "feat_003       NaN       NaN       NaN  \n",
       "feat_004       NaN       NaN       NaN  \n",
       "feat_005       NaN       NaN  0.001686  \n",
       "\n",
       "[5 rows x 257 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations=df_train.corr()\n",
    "correlations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many NaN values for the correlations, this could imply the existence of 0 variance features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "description=df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>feat_009</th>\n",
       "      <th>feat_010</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_248</th>\n",
       "      <th>feat_249</th>\n",
       "      <th>feat_250</th>\n",
       "      <th>feat_251</th>\n",
       "      <th>feat_252</th>\n",
       "      <th>feat_253</th>\n",
       "      <th>feat_254</th>\n",
       "      <th>feat_255</th>\n",
       "      <th>feat_256</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.00000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.642013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.47765</td>\n",
       "      <td>0.975860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.917407</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.218787</td>\n",
       "      <td>0.037309</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.915726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.479409</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003606</td>\n",
       "      <td>0.49950</td>\n",
       "      <td>0.153484</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.413424</td>\n",
       "      <td>0.189518</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.407176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             feat_001  feat_002  feat_003  feat_004        feat_005  \\\n",
       "count  1000000.000000   1000000   1000000   1000000  1000000.000000   \n",
       "mean         0.642013         0         0         0        0.999987   \n",
       "std          0.479409         0         0         0        0.003606   \n",
       "min          0.000000         0         0         0        0.000000   \n",
       "25%          0.000000         0         0         0        1.000000   \n",
       "50%          1.000000         0         0         0        1.000000   \n",
       "75%          1.000000         0         0         0        1.000000   \n",
       "max          1.000000         0         0         0        1.000000   \n",
       "\n",
       "            feat_006        feat_007  feat_008  feat_009  feat_010  \\\n",
       "count  1000000.00000  1000000.000000   1000000   1000000   1000000   \n",
       "mean         0.47765        0.975860         0         0         0   \n",
       "std          0.49950        0.153484         0         0         0   \n",
       "min          0.00000        0.000000         0         0         0   \n",
       "25%          0.00000        1.000000         0         0         0   \n",
       "50%          0.00000        1.000000         0         0         0   \n",
       "75%          1.00000        1.000000         0         0         0   \n",
       "max          1.00000        1.000000         0         0         0   \n",
       "\n",
       "            ...              feat_248  feat_249  feat_250        feat_251  \\\n",
       "count       ...        1000000.000000   1000000   1000000  1000000.000000   \n",
       "mean        ...              0.917407         0         0        0.218787   \n",
       "std         ...              0.275266         0         0        0.413424   \n",
       "min         ...              0.000000         0         0        0.000000   \n",
       "25%         ...              1.000000         0         0        0.000000   \n",
       "50%         ...              1.000000         0         0        0.000000   \n",
       "75%         ...              1.000000         0         0        0.000000   \n",
       "max         ...              1.000000         0         0        1.000000   \n",
       "\n",
       "             feat_252  feat_253  feat_254  feat_255  feat_256             gap  \n",
       "count  1000000.000000   1000000   1000000   1000000   1000000  1000000.000000  \n",
       "mean         0.037309         0         0         0         0        1.915726  \n",
       "std          0.189518         0         0         0         0        0.407176  \n",
       "min          0.000000         0         0         0         0       -1.440000  \n",
       "25%          0.000000         0         0         0         0        1.620000  \n",
       "50%          0.000000         0         0         0         0        1.910000  \n",
       "75%          0.000000         0         0         0         0        2.200000  \n",
       "max          1.000000         0         0         0         0        3.800000  \n",
       "\n",
       "[8 rows x 257 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many features appear to be entirely made of zeros, let's see how many have non-zero standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_transp=description.transpose()\n",
    "np.sum(desc_transp['std']>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we list the features with non-zero standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features=desc_transp[desc_transp['std']>0].index\n",
    "features=list(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will also include the smiles column as it may be useful in future feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "desc_feat=['smiles']\n",
    "all_features=desc_feat+features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#truncate df with relevant features\n",
    "df_small=df_train[all_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_025</th>\n",
       "      <th>feat_037</th>\n",
       "      <th>feat_044</th>\n",
       "      <th>feat_068</th>\n",
       "      <th>feat_069</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_200</th>\n",
       "      <th>feat_208</th>\n",
       "      <th>feat_218</th>\n",
       "      <th>feat_225</th>\n",
       "      <th>feat_226</th>\n",
       "      <th>feat_243</th>\n",
       "      <th>feat_248</th>\n",
       "      <th>feat_251</th>\n",
       "      <th>feat_252</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  feat_001  feat_005  \\\n",
       "0  c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...         0         1   \n",
       "1  C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...         1         1   \n",
       "2  [nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...         1         1   \n",
       "3  [nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...         1         1   \n",
       "4     c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1         0         1   \n",
       "\n",
       "   feat_006  feat_007  feat_025  feat_037  feat_044  feat_068  feat_069  ...   \\\n",
       "0         0         1         0         0         0         1         0  ...    \n",
       "1         0         1         1         1         0         0         1  ...    \n",
       "2         1         1         0         1         0         1         1  ...    \n",
       "3         1         1         1         0         0         1         0  ...    \n",
       "4         0         1         0         0         0         0         0  ...    \n",
       "\n",
       "   feat_200  feat_208  feat_218  feat_225  feat_226  feat_243  feat_248  \\\n",
       "0         0         0         0         0         1         0         1   \n",
       "1         0         0         1         0         1         0         1   \n",
       "2         0         0         0         0         1         1         1   \n",
       "3         0         0         1         0         1         1         1   \n",
       "4         0         1         0         0         1         0         1   \n",
       "\n",
       "   feat_251  feat_252   gap  \n",
       "0         0         0  1.19  \n",
       "1         1         0  1.60  \n",
       "2         0         1  1.49  \n",
       "3         0         1  1.36  \n",
       "4         0         0  1.98  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_025</th>\n",
       "      <th>feat_037</th>\n",
       "      <th>feat_044</th>\n",
       "      <th>feat_068</th>\n",
       "      <th>feat_069</th>\n",
       "      <th>feat_072</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_200</th>\n",
       "      <th>feat_208</th>\n",
       "      <th>feat_218</th>\n",
       "      <th>feat_225</th>\n",
       "      <th>feat_226</th>\n",
       "      <th>feat_243</th>\n",
       "      <th>feat_248</th>\n",
       "      <th>feat_251</th>\n",
       "      <th>feat_252</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feat_001</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_005</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_006</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_007</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_025</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_037</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_044</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_068</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_069</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_072</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_087</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_090</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_102</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_119</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_123</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_126</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_132</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_173</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_176</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_187</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_196</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_199</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_200</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_208</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_218</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_225</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_226</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_243</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_248</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_251</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_252</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gap</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          feat_001  feat_005  feat_006  feat_007  feat_025  feat_037  \\\n",
       "feat_001         1       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_005       NaN         1       NaN       NaN       NaN       NaN   \n",
       "feat_006       NaN       NaN         1       NaN       NaN       NaN   \n",
       "feat_007       NaN       NaN       NaN         1       NaN       NaN   \n",
       "feat_025       NaN       NaN       NaN       NaN         1       NaN   \n",
       "feat_037       NaN       NaN       NaN       NaN       NaN         1   \n",
       "feat_044       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_068       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_069       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_072       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_087       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_090       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_102       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_119       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_123       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_126       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_132       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_173       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_176       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_187       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_196       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_199       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_200       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_208       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_218       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_225       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_226       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_243       NaN       NaN         1       NaN       NaN       NaN   \n",
       "feat_248       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_251       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_252       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "gap            NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "          feat_044  feat_068  feat_069  feat_072 ...   feat_200  feat_208  \\\n",
       "feat_001       NaN       NaN       NaN       NaN ...        NaN       NaN   \n",
       "feat_005       NaN       NaN       NaN       NaN ...        NaN       NaN   \n",
       "feat_006       NaN       NaN       NaN       NaN ...        NaN       NaN   \n",
       "feat_007       NaN       NaN       NaN       NaN ...        NaN       NaN   \n",
       "feat_025       NaN       NaN       NaN       NaN ...        NaN       NaN   \n",
       "feat_037       NaN       NaN       NaN       NaN ...        NaN       NaN   \n",
       "feat_044         1       NaN       NaN       NaN ...        NaN       NaN   \n",
       "feat_068       NaN         1       NaN       NaN ...        NaN       NaN   \n",
       "feat_069       NaN       NaN         1       NaN ...        NaN       NaN   \n",
       "feat_072       NaN       NaN       NaN         1 ...        NaN       NaN   \n",
       "feat_087       NaN       NaN       NaN       NaN ...        NaN       NaN   \n",
       "feat_090       NaN       NaN       NaN       NaN ...        NaN       NaN   \n",
       "feat_102       NaN       NaN       NaN       NaN ...        NaN       NaN   \n",
       "feat_119       NaN       NaN       NaN       NaN ...        NaN       NaN   \n",
       "feat_123       NaN       NaN       NaN       NaN ...        NaN       NaN   \n",
       "feat_126       NaN       NaN       NaN       NaN ...        NaN       NaN   \n",
       "feat_132       NaN       NaN       NaN       NaN ...        NaN       NaN   \n",
       "feat_173       NaN       NaN       NaN       NaN ...        NaN       NaN   \n",
       "feat_176       NaN       NaN       NaN       NaN ...        NaN       NaN   \n",
       "feat_187       NaN       NaN       NaN       NaN ...        NaN       NaN   \n",
       "feat_196       NaN       NaN       NaN       NaN ...        NaN       NaN   \n",
       "feat_199       NaN       NaN       NaN       NaN ...          1       NaN   \n",
       "feat_200       NaN       NaN       NaN       NaN ...          1       NaN   \n",
       "feat_208       NaN       NaN       NaN       NaN ...        NaN         1   \n",
       "feat_218       NaN       NaN       NaN       NaN ...        NaN       NaN   \n",
       "feat_225       NaN       NaN       NaN       NaN ...        NaN       NaN   \n",
       "feat_226       NaN       NaN       NaN       NaN ...        NaN       NaN   \n",
       "feat_243       NaN       NaN       NaN       NaN ...        NaN       NaN   \n",
       "feat_248       NaN       NaN       NaN       NaN ...        NaN       NaN   \n",
       "feat_251       NaN       NaN       NaN       NaN ...        NaN       NaN   \n",
       "feat_252       NaN       NaN       NaN       NaN ...        NaN       NaN   \n",
       "gap            NaN       NaN       NaN       NaN ...        NaN       NaN   \n",
       "\n",
       "          feat_218  feat_225  feat_226  feat_243  feat_248  feat_251  \\\n",
       "feat_001       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_005       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_006       NaN       NaN       NaN         1       NaN       NaN   \n",
       "feat_007       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_025       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_037       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_044       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_068       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_069       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_072       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_087       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_090       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_102         1       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_119       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_123       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_126       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_132       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_173       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_176       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_187       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_196       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_199       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_200       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_208       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_218         1       NaN       NaN       NaN       NaN       NaN   \n",
       "feat_225       NaN         1       NaN       NaN       NaN       NaN   \n",
       "feat_226       NaN       NaN         1       NaN       NaN       NaN   \n",
       "feat_243       NaN       NaN       NaN         1       NaN       NaN   \n",
       "feat_248       NaN       NaN       NaN       NaN         1       NaN   \n",
       "feat_251       NaN       NaN       NaN       NaN       NaN         1   \n",
       "feat_252       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "gap            NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "          feat_252  gap  \n",
       "feat_001       NaN  NaN  \n",
       "feat_005       NaN  NaN  \n",
       "feat_006       NaN  NaN  \n",
       "feat_007       NaN  NaN  \n",
       "feat_025       NaN  NaN  \n",
       "feat_037       NaN  NaN  \n",
       "feat_044       NaN  NaN  \n",
       "feat_068       NaN  NaN  \n",
       "feat_069       NaN  NaN  \n",
       "feat_072       NaN  NaN  \n",
       "feat_087       NaN  NaN  \n",
       "feat_090       NaN  NaN  \n",
       "feat_102       NaN  NaN  \n",
       "feat_119       NaN  NaN  \n",
       "feat_123       NaN  NaN  \n",
       "feat_126       NaN  NaN  \n",
       "feat_132       NaN  NaN  \n",
       "feat_173       NaN  NaN  \n",
       "feat_176       NaN  NaN  \n",
       "feat_187       NaN  NaN  \n",
       "feat_196       NaN  NaN  \n",
       "feat_199       NaN  NaN  \n",
       "feat_200       NaN  NaN  \n",
       "feat_208       NaN  NaN  \n",
       "feat_218       NaN  NaN  \n",
       "feat_225       NaN  NaN  \n",
       "feat_226       NaN  NaN  \n",
       "feat_243       NaN  NaN  \n",
       "feat_248       NaN  NaN  \n",
       "feat_251       NaN  NaN  \n",
       "feat_252         1  NaN  \n",
       "gap            NaN    1  \n",
       "\n",
       "[32 rows x 32 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#From the truncated features, let's see if there are duplicate (or correlation=1) features\n",
    "corr_small=df_small.corr()\n",
    "corr_small[corr_small==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(22, 21), (24, 12), (27, 2)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#return only correlations==1\n",
    "test=np.array(corr_small[corr_small==1].values)\n",
    "\n",
    "#replace nan values with 0\n",
    "where_are_NaNs = np.isnan(test)\n",
    "test[where_are_NaNs] = 0\n",
    "\n",
    "#replace diagonal values with 0\n",
    "n = test.shape[0]\n",
    "test[range(n), range(n)] = 0\n",
    "\n",
    "#replace above diagonal with zero, as to not repeat feature pairs\n",
    "test=np.tril(test, k=0)\n",
    "\n",
    "#return indices of non-zero values\n",
    "indices=np.nonzero(test)\n",
    "tupindices=zip(list(indices[0]), list(indices[1]))\n",
    "tupindices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we drop one feature from each perfectly correlated pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_200 and feat_199\n",
      "feat_218 and feat_102\n",
      "feat_243 and feat_006\n"
     ]
    }
   ],
   "source": [
    "drop_feat=[]\n",
    "for i, j in tupindices:\n",
    "    print df_small.columns[i]+\" and \"+df_small.columns[j]\n",
    "    drop_feat.append(df_small.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feat_200', 'feat_218', 'feat_243']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_final=df_small.drop(drop_feat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_025</th>\n",
       "      <th>feat_037</th>\n",
       "      <th>feat_044</th>\n",
       "      <th>feat_068</th>\n",
       "      <th>feat_069</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_187</th>\n",
       "      <th>feat_196</th>\n",
       "      <th>feat_199</th>\n",
       "      <th>feat_208</th>\n",
       "      <th>feat_225</th>\n",
       "      <th>feat_226</th>\n",
       "      <th>feat_248</th>\n",
       "      <th>feat_251</th>\n",
       "      <th>feat_252</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  feat_001  feat_005  \\\n",
       "0  c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...         0         1   \n",
       "1  C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...         1         1   \n",
       "2  [nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...         1         1   \n",
       "3  [nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...         1         1   \n",
       "4     c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1         0         1   \n",
       "\n",
       "   feat_006  feat_007  feat_025  feat_037  feat_044  feat_068  feat_069  ...   \\\n",
       "0         0         1         0         0         0         1         0  ...    \n",
       "1         0         1         1         1         0         0         1  ...    \n",
       "2         1         1         0         1         0         1         1  ...    \n",
       "3         1         1         1         0         0         1         0  ...    \n",
       "4         0         1         0         0         0         0         0  ...    \n",
       "\n",
       "   feat_187  feat_196  feat_199  feat_208  feat_225  feat_226  feat_248  \\\n",
       "0         0         0         0         0         0         1         1   \n",
       "1         1         0         0         0         0         1         1   \n",
       "2         0         0         0         0         0         1         1   \n",
       "3         0         0         0         0         0         1         1   \n",
       "4         0         0         0         1         0         1         1   \n",
       "\n",
       "   feat_251  feat_252   gap  \n",
       "0         0         0  1.19  \n",
       "1         1         0  1.60  \n",
       "2         0         1  1.49  \n",
       "3         0         1  1.36  \n",
       "4         0         0  1.98  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN/TEST SPLIT AND FILE OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "itrain, ival = train_test_split(xrange(df_final.shape[0]), train_size=0.9, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask=np.zeros(df_final.shape[0], dtype='int')\n",
    "mask[itrain]=1\n",
    "mask = (mask==1)\n",
    "df_final_train=df_final[mask]\n",
    "df_final_val=df_final[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(899997, 30)\n",
      "(100000, 30)\n"
     ]
    }
   ],
   "source": [
    "print df_final_train.shape\n",
    "print df_final_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we test to see if the validation response data fits a similar distribution to the entire training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9160156 0.407367755912\n",
      "1.9157342872 0.407148592603\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# Fit a normal distribution to the validation data and compare with total data\n",
    "mu2, std2 = norm.fit(df_final_val.gap)\n",
    "print mu2, std2 #from validation set\n",
    "print mu, std #from all training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final_train.to_csv('new_train.csv')\n",
    "df_final_val.to_csv('new_val.csv')\n",
    "#MAKE SURE TO USE index_col=0 when you read the data into pandas (see below)\n",
    "#df_read=pd.read_csv('new_val', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_final_train=pd.read_csv('new_train.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_025</th>\n",
       "      <th>feat_037</th>\n",
       "      <th>feat_044</th>\n",
       "      <th>feat_068</th>\n",
       "      <th>feat_069</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_187</th>\n",
       "      <th>feat_196</th>\n",
       "      <th>feat_199</th>\n",
       "      <th>feat_208</th>\n",
       "      <th>feat_225</th>\n",
       "      <th>feat_226</th>\n",
       "      <th>feat_248</th>\n",
       "      <th>feat_251</th>\n",
       "      <th>feat_252</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c1ccc(o1)-c1cc2cc3cc4c5c[nH]cc5ccc4cc3cc2o1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  feat_001  feat_005  \\\n",
       "1  C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...         1         1   \n",
       "2  [nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...         1         1   \n",
       "3  [nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...         1         1   \n",
       "4     c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1         0         1   \n",
       "8        c1ccc(o1)-c1cc2cc3cc4c5c[nH]cc5ccc4cc3cc2o1         0         1   \n",
       "\n",
       "   feat_006  feat_007  feat_025  feat_037  feat_044  feat_068  feat_069  ...   \\\n",
       "1         0         1         1         1         0         0         1  ...    \n",
       "2         1         1         0         1         0         1         1  ...    \n",
       "3         1         1         1         0         0         1         0  ...    \n",
       "4         0         1         0         0         0         0         0  ...    \n",
       "8         1         1         0         0         0         1         0  ...    \n",
       "\n",
       "   feat_187  feat_196  feat_199  feat_208  feat_225  feat_226  feat_248  \\\n",
       "1         1         0         0         0         0         1         1   \n",
       "2         0         0         0         0         0         1         1   \n",
       "3         0         0         0         0         0         1         1   \n",
       "4         0         0         0         1         0         1         1   \n",
       "8         0         0         0         0         1         1         1   \n",
       "\n",
       "   feat_251  feat_252   gap  \n",
       "1         1         0  1.60  \n",
       "2         0         1  1.49  \n",
       "3         0         1  1.36  \n",
       "4         0         0  1.98  \n",
       "8         0         0  2.19  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_feat=list(df_final_train.columns)\n",
    "test_feat.remove('gap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "df_final_test=df_test[test_feat]\n",
    "df_final_test.to_csv('new_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat=list(df_final_train.columns)\n",
    "feat.remove('smiles')\n",
    "feat.remove('gap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_samp=df_final_train.sample(n=200000, replace=False, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST {'subsample': 0.8, 'colsample_bytree': 0.75, 'max_depth': 10} -0.0737503972675 [mean: -0.07553, std: 0.00060, params: {'subsample': 0.5, 'colsample_bytree': 0.5, 'max_depth': 6}, mean: -0.07512, std: 0.00036, params: {'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 6}, mean: -0.07524, std: 0.00065, params: {'subsample': 1, 'colsample_bytree': 0.5, 'max_depth': 6}, mean: -0.07407, std: 0.00060, params: {'subsample': 0.5, 'colsample_bytree': 0.5, 'max_depth': 8}, mean: -0.07429, std: 0.00074, params: {'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 8}, mean: -0.07398, std: 0.00062, params: {'subsample': 1, 'colsample_bytree': 0.5, 'max_depth': 8}, mean: -0.07390, std: 0.00060, params: {'subsample': 0.5, 'colsample_bytree': 0.5, 'max_depth': 10}, mean: -0.07417, std: 0.00045, params: {'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 10}, mean: -0.07446, std: 0.00098, params: {'subsample': 1, 'colsample_bytree': 0.5, 'max_depth': 10}, mean: -0.07460, std: 0.00093, params: {'subsample': 0.5, 'colsample_bytree': 0.75, 'max_depth': 6}, mean: -0.07438, std: 0.00060, params: {'subsample': 0.8, 'colsample_bytree': 0.75, 'max_depth': 6}, mean: -0.07467, std: 0.00062, params: {'subsample': 1, 'colsample_bytree': 0.75, 'max_depth': 6}, mean: -0.07390, std: 0.00061, params: {'subsample': 0.5, 'colsample_bytree': 0.75, 'max_depth': 8}, mean: -0.07417, std: 0.00080, params: {'subsample': 0.8, 'colsample_bytree': 0.75, 'max_depth': 8}, mean: -0.07447, std: 0.00053, params: {'subsample': 1, 'colsample_bytree': 0.75, 'max_depth': 8}, mean: -0.07380, std: 0.00057, params: {'subsample': 0.5, 'colsample_bytree': 0.75, 'max_depth': 10}, mean: -0.07375, std: 0.00060, params: {'subsample': 0.8, 'colsample_bytree': 0.75, 'max_depth': 10}, mean: -0.07383, std: 0.00058, params: {'subsample': 1, 'colsample_bytree': 0.75, 'max_depth': 10}, mean: -0.07433, std: 0.00061, params: {'subsample': 0.5, 'colsample_bytree': 1, 'max_depth': 6}, mean: -0.07489, std: 0.00102, params: {'subsample': 0.8, 'colsample_bytree': 1, 'max_depth': 6}, mean: -0.07459, std: 0.00067, params: {'subsample': 1, 'colsample_bytree': 1, 'max_depth': 6}, mean: -0.07450, std: 0.00058, params: {'subsample': 0.5, 'colsample_bytree': 1, 'max_depth': 8}, mean: -0.07385, std: 0.00058, params: {'subsample': 0.8, 'colsample_bytree': 1, 'max_depth': 8}, mean: -0.07422, std: 0.00048, params: {'subsample': 1, 'colsample_bytree': 1, 'max_depth': 8}, mean: -0.07413, std: 0.00123, params: {'subsample': 0.5, 'colsample_bytree': 1, 'max_depth': 10}, mean: -0.07519, std: 0.00103, params: {'subsample': 0.8, 'colsample_bytree': 1, 'max_depth': 10}, mean: -0.07414, std: 0.00094, params: {'subsample': 1, 'colsample_bytree': 1, 'max_depth': 10}]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "params = {\"max_depth\": [6, 8, 10],\n",
    "          'colsample_bytree':[0.5,0.75,1],\n",
    "          'subsample':[0.5,0.8,1]}\n",
    "\n",
    "gbrt = xgb.XGBRegressor(nthread=-1, learning_rate=0.05, n_estimators=1000, silent=0, seed=50)\n",
    "\n",
    "cv = GridSearchCV(gbrt, param_grid=params, cv=5, n_jobs=-1, scoring='mean_squared_error')\n",
    "cv.fit(df_samp[feat].values, df_samp['gap'].values)\n",
    "print \"BEST\", cv.best_params_, cv.best_score_, cv.grid_scores_\n",
    "best = cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train model with optimal parameters\n",
    "gbrt_final=xgb.XGBRegressor(nthread=-1, learning_rate=0.02, n_estimators=2000, silent=0, \n",
    "                            seed=50, subsample= 0.8, colsample_bytree= 0.75, max_depth= 10)\n",
    "gbrt_final=gbrt_final.fit(df_final_train[feat], df_final_train['gap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tempdata/gbrt.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pickle model\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(gbrt_final, 'tempdata/gbrt.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREDICT ON TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test.csv\", index_col=0)\n",
    "y_hat=gbrt_final.predict(df_test[feat])\n",
    "submit=pd.DataFrame(df_test['Id'])\n",
    "submit['Prediction']=y_hat\n",
    "submit.set_index('Id', inplace=True)\n",
    "submit.to_csv('gbrt_baseline_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREDICT ON VALIDATION SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_val = pd.read_csv(\"new_val.csv\", index_col=0)\n",
    "y_hat=gbrt_final.predict(df_val[feat])\n",
    "submit=pd.DataFrame(df_val.index)\n",
    "submit['Prediction']=y_hat\n",
    "submit.set_index(0, inplace=True)\n",
    "submit.to_csv('gbrt_baseline_val.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST WITH FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of model with 13 new features extracted from RDKit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_fe=pd.read_csv('new_tr_feat.csv', index_col=0)\n",
    "feat_new=list(df_fe.columns)\n",
    "feat_new.remove('smiles')\n",
    "feat_new.remove('gap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary cross validation with reduced number of trees and increased learning rate to get idea of RMSE improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(df_fe[feat_new], df_fe['gap']) \n",
    "\n",
    "paramcv = {\n",
    "    'booster' : \"gbtree\",\n",
    "    'silent': 0,\n",
    "    'eta'  :0.3,\n",
    "    'max_depth':10, \n",
    "    'min_child_weight':1, \n",
    "    'subsample': 0.8, \n",
    "    'colsample_bytree':0.75, \n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'seed':500 \n",
    "    }\n",
    "\n",
    "test=xgb.cv(paramcv, dtrain, 100, nfold=3, metrics={'rmse'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.043053</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>1.042983</td>\n",
       "      <td>0.001102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.743957</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.743818</td>\n",
       "      <td>0.000493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.538573</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.538322</td>\n",
       "      <td>0.000370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.400289</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.399848</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.309185</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.308463</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.252030</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.250974</td>\n",
       "      <td>0.000556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.217499</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.216099</td>\n",
       "      <td>0.000385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.197263</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.195534</td>\n",
       "      <td>0.000246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.186048</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.184031</td>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.179273</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.177003</td>\n",
       "      <td>0.000343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.175307</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.172820</td>\n",
       "      <td>0.000423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.172877</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.170198</td>\n",
       "      <td>0.000367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.171188</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.168326</td>\n",
       "      <td>0.000490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.169562</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.166508</td>\n",
       "      <td>0.000361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.168537</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.165335</td>\n",
       "      <td>0.000557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.167823</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.164505</td>\n",
       "      <td>0.000489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.167147</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.163693</td>\n",
       "      <td>0.000285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.166464</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.162867</td>\n",
       "      <td>0.000092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.166008</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.162288</td>\n",
       "      <td>0.000119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.165786</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.162012</td>\n",
       "      <td>0.000196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.165259</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.161375</td>\n",
       "      <td>0.000227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.164647</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.160620</td>\n",
       "      <td>0.000311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.164425</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.160320</td>\n",
       "      <td>0.000253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.164086</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.159850</td>\n",
       "      <td>0.000477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.163557</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.159186</td>\n",
       "      <td>0.000176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.163257</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.158835</td>\n",
       "      <td>0.000290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.162903</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.158404</td>\n",
       "      <td>0.000424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.162518</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.161880</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.157135</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.161534</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.156667</td>\n",
       "      <td>0.000146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.153319</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.145369</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.153202</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.145194</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.153118</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.145057</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.152991</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.144861</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.152898</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.144697</td>\n",
       "      <td>0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.152771</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.144504</td>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.152699</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.144388</td>\n",
       "      <td>0.000198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.152579</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.144197</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.152504</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.144074</td>\n",
       "      <td>0.000158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.152442</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.143960</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.152374</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.143840</td>\n",
       "      <td>0.000172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.152299</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.143725</td>\n",
       "      <td>0.000169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.152221</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.143591</td>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.152167</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.143482</td>\n",
       "      <td>0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.152105</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.143371</td>\n",
       "      <td>0.000133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.152021</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.143217</td>\n",
       "      <td>0.000146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.151962</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.143116</td>\n",
       "      <td>0.000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.151897</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.143002</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.151812</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.142823</td>\n",
       "      <td>0.000215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.151755</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.142725</td>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.151678</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.142595</td>\n",
       "      <td>0.000202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.151582</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.142446</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.151545</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.142346</td>\n",
       "      <td>0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.151462</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.142221</td>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.151390</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.142074</td>\n",
       "      <td>0.000264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.151330</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.141954</td>\n",
       "      <td>0.000249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.151273</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.141848</td>\n",
       "      <td>0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.151180</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.141700</td>\n",
       "      <td>0.000231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.151134</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.141589</td>\n",
       "      <td>0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.151065</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.141471</td>\n",
       "      <td>0.000185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    test-rmse-mean  test-rmse-std  train-rmse-mean  train-rmse-std\n",
       "0         1.043053       0.001062         1.042983        0.001102\n",
       "1         0.743957       0.000386         0.743818        0.000493\n",
       "2         0.538573       0.000325         0.538322        0.000370\n",
       "3         0.400289       0.000151         0.399848        0.000050\n",
       "4         0.309185       0.000483         0.308463        0.000277\n",
       "5         0.252030       0.000536         0.250974        0.000556\n",
       "6         0.217499       0.000521         0.216099        0.000385\n",
       "7         0.197263       0.000254         0.195534        0.000246\n",
       "8         0.186048       0.000507         0.184031        0.000572\n",
       "9         0.179273       0.000333         0.177003        0.000343\n",
       "10        0.175307       0.000421         0.172820        0.000423\n",
       "11        0.172877       0.000290         0.170198        0.000367\n",
       "12        0.171188       0.000317         0.168326        0.000490\n",
       "13        0.169562       0.000108         0.166508        0.000361\n",
       "14        0.168537       0.000339         0.165335        0.000557\n",
       "15        0.167823       0.000273         0.164505        0.000489\n",
       "16        0.167147       0.000121         0.163693        0.000285\n",
       "17        0.166464       0.000079         0.162867        0.000092\n",
       "18        0.166008       0.000083         0.162288        0.000119\n",
       "19        0.165786       0.000107         0.162012        0.000196\n",
       "20        0.165259       0.000137         0.161375        0.000227\n",
       "21        0.164647       0.000143         0.160620        0.000311\n",
       "22        0.164425       0.000080         0.160320        0.000253\n",
       "23        0.164086       0.000264         0.159850        0.000477\n",
       "24        0.163557       0.000061         0.159186        0.000176\n",
       "25        0.163257       0.000168         0.158835        0.000290\n",
       "26        0.162903       0.000203         0.158404        0.000424\n",
       "27        0.162518       0.000250         0.157895        0.000453\n",
       "28        0.161880       0.000109         0.157135        0.000054\n",
       "29        0.161534       0.000169         0.156667        0.000146\n",
       "..             ...            ...              ...             ...\n",
       "70        0.153319       0.000242         0.145369        0.000141\n",
       "71        0.153202       0.000175         0.145194        0.000076\n",
       "72        0.153118       0.000168         0.145057        0.000074\n",
       "73        0.152991       0.000152         0.144861        0.000110\n",
       "74        0.152898       0.000115         0.144697        0.000128\n",
       "75        0.152771       0.000113         0.144504        0.000149\n",
       "76        0.152699       0.000116         0.144388        0.000198\n",
       "77        0.152579       0.000125         0.144197        0.000134\n",
       "78        0.152504       0.000136         0.144074        0.000158\n",
       "79        0.152442       0.000122         0.143960        0.000134\n",
       "80        0.152374       0.000150         0.143840        0.000172\n",
       "81        0.152299       0.000117         0.143725        0.000169\n",
       "82        0.152221       0.000105         0.143591        0.000149\n",
       "83        0.152167       0.000108         0.143482        0.000128\n",
       "84        0.152105       0.000100         0.143371        0.000133\n",
       "85        0.152021       0.000095         0.143217        0.000146\n",
       "86        0.151962       0.000060         0.143116        0.000180\n",
       "87        0.151897       0.000037         0.143002        0.000217\n",
       "88        0.151812       0.000086         0.142823        0.000215\n",
       "89        0.151755       0.000118         0.142725        0.000210\n",
       "90        0.151678       0.000095         0.142595        0.000202\n",
       "91        0.151582       0.000089         0.142446        0.000239\n",
       "92        0.151545       0.000072         0.142346        0.000259\n",
       "93        0.151462       0.000105         0.142221        0.000257\n",
       "94        0.151390       0.000070         0.142074        0.000264\n",
       "95        0.151330       0.000078         0.141954        0.000249\n",
       "96        0.151273       0.000089         0.141848        0.000232\n",
       "97        0.151180       0.000131         0.141700        0.000231\n",
       "98        0.151134       0.000164         0.141589        0.000232\n",
       "99        0.151065       0.000164         0.141471        0.000185\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a significant improvement, so we will train the model with 1000 trees and reduced learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbrt_fe=xgb.XGBRegressor(nthread=-1, learning_rate=0.02, n_estimators=1000, silent=0, seed=50,\n",
    "                           subsample= 0.8, colsample_bytree= 0.75, max_depth= 10)\n",
    "gbrt_fe=gbrt_fe.fit(df_fe[feat_new], df_fe['gap'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREDICT ON TEST AND VALIDATION SETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joblib.dump(gbrt_fe, 'tempdata/gbrt_fe.pkl') \n",
    "df_fe_te = pd.read_csv('new_te_feat.csv', index_col=0)\n",
    "y_hat=gbrt_fe.predict(df_fe_te[feat_new])\n",
    "submit=pd.DataFrame(df_test['Id'])\n",
    "submit['Prediction']=y_hat\n",
    "submit.set_index('Id', inplace=True)\n",
    "submit.to_csv('gbrt_fe_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Predict on validation set\n",
    "df_fe_val = pd.read_csv('new_val_feat.csv', index_col=0)\n",
    "y_hat=gbrt_fe.predict(df_fe_val[feat_new])\n",
    "submit=pd.DataFrame(df_fe_val.index)\n",
    "submit['Prediction']=y_hat\n",
    "submit.set_index(0, inplace=True)\n",
    "submit.to_csv('gbrt_fe_val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# XGBOOST WITH MORE FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_xfe=pd.read_csv('new_xtr_feat.csv', index_col=0)\n",
    "feat_new=list(df_xfe.columns)\n",
    "feat_new.remove('smiles')\n",
    "feat_new.remove('gap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(df_xfe[feat_new], df_xfe['gap']) \n",
    "\n",
    "paramcv = {\n",
    "    'booster' : \"gbtree\",\n",
    "    'silent': 0,\n",
    "    'eta'  :0.3,\n",
    "    'max_depth':10, \n",
    "    'min_child_weight':1, \n",
    "    'subsample': 0.8, \n",
    "    'colsample_bytree':0.75, \n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'seed':500 \n",
    "    }\n",
    "\n",
    "test=xgb.cv(paramcv, dtrain, 100, nfold=3, metrics={'rmse'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.041350</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>1.041308</td>\n",
       "      <td>0.000324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.741443</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.741323</td>\n",
       "      <td>0.000288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.535147</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.534812</td>\n",
       "      <td>0.000293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.395462</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.394851</td>\n",
       "      <td>0.000209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.302985</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.302042</td>\n",
       "      <td>0.000480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.244275</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.242883</td>\n",
       "      <td>0.000642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.208284</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.206395</td>\n",
       "      <td>0.000473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.187278</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.184918</td>\n",
       "      <td>0.000479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.175332</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.172521</td>\n",
       "      <td>0.000555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.168343</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.165172</td>\n",
       "      <td>0.000486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.164232</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.160743</td>\n",
       "      <td>0.000503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.161709</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.157907</td>\n",
       "      <td>0.000234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.160077</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.156013</td>\n",
       "      <td>0.000271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.158844</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.154573</td>\n",
       "      <td>0.000360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.157845</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.153355</td>\n",
       "      <td>0.000370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.157074</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.152378</td>\n",
       "      <td>0.000306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.156484</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.151601</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.155906</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.150817</td>\n",
       "      <td>0.000347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.155413</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.150167</td>\n",
       "      <td>0.000513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.154964</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.149546</td>\n",
       "      <td>0.000638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.154334</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.148738</td>\n",
       "      <td>0.000517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.153871</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.148060</td>\n",
       "      <td>0.000608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.153432</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.147464</td>\n",
       "      <td>0.000534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.153125</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.147018</td>\n",
       "      <td>0.000403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.152487</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.146144</td>\n",
       "      <td>0.000399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.152187</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.145698</td>\n",
       "      <td>0.000274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.151909</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.145266</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.151654</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.144891</td>\n",
       "      <td>0.000344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.151455</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.144567</td>\n",
       "      <td>0.000203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.151240</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.144237</td>\n",
       "      <td>0.000224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.142767</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.130018</td>\n",
       "      <td>0.000341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.142669</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.129790</td>\n",
       "      <td>0.000348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.142597</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.129645</td>\n",
       "      <td>0.000296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.142443</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.129310</td>\n",
       "      <td>0.000295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.142339</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.129106</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.142213</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.128871</td>\n",
       "      <td>0.000224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.142121</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.128680</td>\n",
       "      <td>0.000186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.142023</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.128457</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.141931</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.128268</td>\n",
       "      <td>0.000208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.141700</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.127951</td>\n",
       "      <td>0.000099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.141514</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.127676</td>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.141436</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.127492</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.141356</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.127252</td>\n",
       "      <td>0.000198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.141267</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.127050</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.141148</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.126833</td>\n",
       "      <td>0.000205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.141029</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.126609</td>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.140966</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.126473</td>\n",
       "      <td>0.000129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.140853</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.126225</td>\n",
       "      <td>0.000203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.140788</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.126082</td>\n",
       "      <td>0.000203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.140692</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.125883</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.140650</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.125766</td>\n",
       "      <td>0.000347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.140553</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.125599</td>\n",
       "      <td>0.000402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.140444</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.125370</td>\n",
       "      <td>0.000363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.140415</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.125254</td>\n",
       "      <td>0.000350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.140239</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.124964</td>\n",
       "      <td>0.000351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.140157</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.124776</td>\n",
       "      <td>0.000368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.140100</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.124634</td>\n",
       "      <td>0.000391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.140015</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.124404</td>\n",
       "      <td>0.000442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.139887</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.124145</td>\n",
       "      <td>0.000398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.139795</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.123946</td>\n",
       "      <td>0.000424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    test-rmse-mean  test-rmse-std  train-rmse-mean  train-rmse-std\n",
       "0         1.041350       0.000299         1.041308        0.000324\n",
       "1         0.741443       0.000252         0.741323        0.000288\n",
       "2         0.535147       0.000199         0.534812        0.000293\n",
       "3         0.395462       0.000090         0.394851        0.000209\n",
       "4         0.302985       0.000340         0.302042        0.000480\n",
       "5         0.244275       0.000470         0.242883        0.000642\n",
       "6         0.208284       0.000316         0.206395        0.000473\n",
       "7         0.187278       0.000338         0.184918        0.000479\n",
       "8         0.175332       0.000421         0.172521        0.000555\n",
       "9         0.168343       0.000381         0.165172        0.000486\n",
       "10        0.164232       0.000453         0.160743        0.000503\n",
       "11        0.161709       0.000301         0.157907        0.000234\n",
       "12        0.160077       0.000352         0.156013        0.000271\n",
       "13        0.158844       0.000393         0.154573        0.000360\n",
       "14        0.157845       0.000438         0.153355        0.000370\n",
       "15        0.157074       0.000400         0.152378        0.000306\n",
       "16        0.156484       0.000296         0.151601        0.000183\n",
       "17        0.155906       0.000385         0.150817        0.000347\n",
       "18        0.155413       0.000527         0.150167        0.000513\n",
       "19        0.154964       0.000637         0.149546        0.000638\n",
       "20        0.154334       0.000516         0.148738        0.000517\n",
       "21        0.153871       0.000572         0.148060        0.000608\n",
       "22        0.153432       0.000528         0.147464        0.000534\n",
       "23        0.153125       0.000435         0.147018        0.000403\n",
       "24        0.152487       0.000425         0.146144        0.000399\n",
       "25        0.152187       0.000320         0.145698        0.000274\n",
       "26        0.151909       0.000295         0.145266        0.000225\n",
       "27        0.151654       0.000384         0.144891        0.000344\n",
       "28        0.151455       0.000312         0.144567        0.000203\n",
       "29        0.151240       0.000366         0.144237        0.000224\n",
       "..             ...            ...              ...             ...\n",
       "70        0.142767       0.000401         0.130018        0.000341\n",
       "71        0.142669       0.000404         0.129790        0.000348\n",
       "72        0.142597       0.000371         0.129645        0.000296\n",
       "73        0.142443       0.000375         0.129310        0.000295\n",
       "74        0.142339       0.000352         0.129106        0.000245\n",
       "75        0.142213       0.000307         0.128871        0.000224\n",
       "76        0.142121       0.000291         0.128680        0.000186\n",
       "77        0.142023       0.000307         0.128457        0.000200\n",
       "78        0.141931       0.000287         0.128268        0.000208\n",
       "79        0.141700       0.000203         0.127951        0.000099\n",
       "80        0.141514       0.000246         0.127676        0.000210\n",
       "81        0.141436       0.000250         0.127492        0.000200\n",
       "82        0.141356       0.000253         0.127252        0.000198\n",
       "83        0.141267       0.000265         0.127050        0.000239\n",
       "84        0.141148       0.000211         0.126833        0.000205\n",
       "85        0.141029       0.000164         0.126609        0.000149\n",
       "86        0.140966       0.000160         0.126473        0.000129\n",
       "87        0.140853       0.000222         0.126225        0.000203\n",
       "88        0.140788       0.000216         0.126082        0.000203\n",
       "89        0.140692       0.000276         0.125883        0.000299\n",
       "90        0.140650       0.000280         0.125766        0.000347\n",
       "91        0.140553       0.000325         0.125599        0.000402\n",
       "92        0.140444       0.000303         0.125370        0.000363\n",
       "93        0.140415       0.000307         0.125254        0.000350\n",
       "94        0.140239       0.000294         0.124964        0.000351\n",
       "95        0.140157       0.000306         0.124776        0.000368\n",
       "96        0.140100       0.000317         0.124634        0.000391\n",
       "97        0.140015       0.000347         0.124404        0.000442\n",
       "98        0.139887       0.000328         0.124145        0.000398\n",
       "99        0.139795       0.000365         0.123946        0.000424\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As completed in the exploratory data analysis, we check for 0 variance features and eliminate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "desc=df_xfe.describe().transpose()\n",
    "to_drop=desc[desc['std']==0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in to_drop:\n",
    "    feat_new.remove(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of model with new features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbrt_xfe=xgb.XGBRegressor(nthread=-1, learning_rate=0.02, n_estimators=1000, silent=0, seed=50,\n",
    "                           subsample= 0.8, colsample_bytree= 0.75, max_depth= 10)\n",
    "gbrt_xfe=gbrt_xfe.fit(df_xfe[feat_new], df_xfe['gap'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREDICT ON TEST AND VALIDATION SETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joblib.dump(gbrt_xfe, 'tempdata/gbrt_xfe.pkl') \n",
    "df_xfe_te = pd.read_csv('new_xte_feat.csv', index_col=0)\n",
    "y_hat=gbrt_xfe.predict(df_xfe_te[feat_new])\n",
    "df_xfe_te.index.name = 'Id'\n",
    "submit=pd.DataFrame(df_xfe_te.index)\n",
    "submit['Prediction']=y_hat\n",
    "submit.set_index('Id', inplace=True)\n",
    "submit.to_csv('gbrt_xfe_test.csv')\n",
    "df_xfe_te.to_csv('new_xte_feat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predict on validation set\n",
    "df_xfe_val = pd.read_csv('new_xval_feat.csv', index_col=0)\n",
    "y_hat=gbrt_xfe.predict(df_xfe_val[feat_new])\n",
    "submit=pd.DataFrame(df_xfe_val.index)\n",
    "submit['Prediction']=y_hat\n",
    "submit.set_index(0, inplace=True)\n",
    "submit.to_csv('gbrt_xfe_val.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
